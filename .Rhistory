labs(x = "Proportion of families in original data with duplicates", y = "") +
scale_color_discrete(name = "Deduplicated") +
facet_grid(factor(metric, levels = c("O/E", "AUC", "rBS")) ~ type,
scales = "free",
switch = "y") +
theme(axis.title.y = element_blank(), # remove the default y-axis title, "wt"
strip.background.y = element_rect(fill = 'transparent'), # replace the strip backgrounds with transparent
strip.placement = 'outside', # put the facet strips on the outside
strip.text.y = element_text(angle = 180)) # rotate the y-axis text (optional)
getwd()
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Simulation/snipR-Simulations/snipR-Simulations/Res_Sim_Effect_af001_dedup.RData")
metrics.mean.dedup
metrics.mean_dedup
metrics.comb %>% filter(pFH == 0.7)
ggplot(metrics.comb %>% filter(pFH == 0.7), aes(pDup, value)) +
geom_line(aes(color = factor(Deduplicated))) +
geom_point(aes(color = factor(Deduplicated))) +
geom_hline(data = metrics.comb %>% filter(pFH == 0.7, pDup == 0, Deduplicated == "No"),
aes(yintercept = value), linetype = "dashed") +
labs(x = "Proportion of families in original data with duplicates", y = "") +
scale_color_discrete(name = "Deduplicated") +
facet_grid(factor(metric, levels = c("O/E", "AUC", "rBS")) ~ type,
scales = "free",
switch = "y") +
theme(axis.title.y = element_blank(), # remove the default y-axis title, "wt"
strip.background.y = element_rect(fill = 'transparent'), # replace the strip backgrounds with transparent
strip.placement = 'outside', # put the facet strips on the outside
strip.text.y = element_text(angle = 180)) # rotate the y-axis text (optional)
ggplot(metrics.comb %>% filter(pFH == 0.7), aes(pDup, value)) +
geom_line(aes(color = factor(Deduplicated))) +
geom_point(aes(color = factor(Deduplicated))) +
geom_hline(data = metrics.comb %>% filter(pFH == 0.7, pDup == 0, Deduplicated == "No"),
aes(yintercept = value), linetype = "dashed") +
labs(x = "Proportion of families in original data with duplicates", y = "") +
scale_color_discrete(name = "Deduplicated") +
facet_grid(factor(metric, levels = c("O/E", "AUC", "rBS")) ~ type,
scales = "free",
switch = "y")
metrics.comb %>% filter(pFH == 0.7)
metrics.comb %>% filter(pFH == 0.7, type == "CV with duplicates")
metrics.comb %>% filter(pFH == 0.7, type == "CV with duplicates", metric == "AUC")
metrics.comb %>% filter(pFH == 0.7, type == "CV with duplicates", metric == "AUC") %>% print()
metrics.comb %>% filter(pFH == 0.7, type == "CV with duplicates", metric == "AUC") %>% print(n=30)
metrics.mean_dedup %>% filter(pFH == 0.7, type == "CV with duplicates", metric == "AUC") %>% print(n=30)
metrics.mean %>% filter(pFH == 0.7, type == "CV with duplicates", metric == "AUC") %>% print(n=30)
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Simulation/snipR-Simulations/snipR-Simulations/Res_Sim_Effect_af001_dedup.RData")
getCI <- function(res, ndigits, comb = FALSE){
if(comb == TRUE){
paste0(format(round(mean(res), ndigits), nsmall = ndigits),
", (", format(round(sort(res)[3], ndigits), nsmall = ndigits),
", ", format(round(sort(res)[97], ndigits), nsmall = ndigits),
")")
} else{
c(format(round(mean(res), ndigits), nsmall = ndigits),
format(round(sort(res)[3], ndigits), nsmall = ndigits),
format(round(sort(res)[97], ndigits), nsmall = ndigits))
}
}
ndigits <- 3
res.oe <- res.auc <- res.rbs <-
lapply(setNames(vector("list", 3), c("cv", "val.ext", "train.ext")),
function(x){
z <- data.frame(matrix(NA, length(pDup.seq), length(pFH.seq)*3))
rownames(z) <- paste0("pDup_", pDup.seq)
colnames(z) <- apply(expand.grid(c("mean", "lo", "up"),
paste0("pFH_", pFH.seq))[, c(2, 1)], 1,
function(x) paste(x[1], x[2], sep = "_"))
return(z)
})
for(i in 1:length(pDup.seq)){
for(j in 1:length(pFH.seq)){
## training and validating on data with duplicates ##
res.oe$cv[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$OE_cv, ndigits)
res.auc$cv[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$AUC_cv, ndigits)
res.rbs$cv[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$rBS_cv, ndigits)
## training on data with duplicates, validating on external data set without duplicates ##
res.oe$val.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$OE_val.ext, ndigits)
res.auc$val.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$AUC_val.ext, ndigits)
res.rbs$val.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$rBS_val.ext, ndigits)
## training on external data without duplicates, validating on data with duplicates ##
res.oe$train.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$OE_train.ext, ndigits)
res.auc$train.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$AUC_train.ext, ndigits)
res.rbs$train.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$rBS_train.ext, ndigits)
}
}
## Plots ##
oe.mean <- lapply(lapply(res.oe, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
auc.mean <- lapply(lapply(res.auc, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
rbs.mean <- lapply(lapply(res.rbs, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
metrics.mean <- rbind(oe.mean$cv %>% mutate(metric = "O/E", type = "CV with duplicates"),
oe.mean$val.ext %>% mutate(metric = "O/E", type = "Train with duplicates, validate without duplicates"),
oe.mean$train.ext %>% mutate(metric = "O/E", type = "Train without duplicates, validate with duplicates"),
auc.mean$cv %>% mutate(metric = "AUC", type = "CV with duplicates"),
auc.mean$val.ext %>% mutate(metric = "AUC", type = "Train with duplicates, validate without duplicates"),
auc.mean$train.ext %>% mutate(metric = "AUC", type = "Train without duplicates, validate with duplicates"),
rbs.mean$cv %>% mutate(metric = "rBS", type = "CV with duplicates"),
rbs.mean$val.ext %>% mutate(metric = "rBS", type = "Train with duplicates, validate without duplicates"),
rbs.mean$train.ext %>% mutate(metric = "rBS", type = "Train without duplicates, validate with duplicates"))
ggplot(metrics.mean, aes(pDup, value)) +
geom_line(aes(color = factor(pFH))) +
geom_point(aes(color = factor(pFH))) +
labs(x = "Proportion of families in original data with duplicates", y = "") +
scale_color_discrete(name = "Among duplicates,\nproportion with \nextensive family \nhistory") +
facet_grid(factor(metric, levels = c("O/E", "AUC", "rBS")) ~ type,
scales = "free",
switch = "y") +
theme(axis.title.y = element_blank(), # remove the default y-axis title, "wt"
strip.background.y = element_rect(fill = 'transparent'), # replace the strip backgrounds with transparent
strip.placement = 'outside', # put the facet strips on the outside
strip.text.y = element_text(angle = 180)) # rotate the y-axis text (optional)
metrics.mean_dedup <- metrics.mean
load(paste0(getwd(), "/Res_Sim_Effect_af001.RData"))
oe.mean <- lapply(lapply(res.oe, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
auc.mean <- lapply(lapply(res.auc, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
rbs.mean <- lapply(lapply(res.rbs, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
metrics.mean <- rbind(oe.mean$cv %>% mutate(metric = "O/E", type = "CV with duplicates"),
oe.mean$val.ext %>% mutate(metric = "O/E", type = "Train with duplicates, validate without duplicates"),
oe.mean$train.ext %>% mutate(metric = "O/E", type = "Train without duplicates, validate with duplicates"),
auc.mean$cv %>% mutate(metric = "AUC", type = "CV with duplicates"),
auc.mean$val.ext %>% mutate(metric = "AUC", type = "Train with duplicates, validate without duplicates"),
auc.mean$train.ext %>% mutate(metric = "AUC", type = "Train without duplicates, validate with duplicates"),
rbs.mean$cv %>% mutate(metric = "rBS", type = "CV with duplicates"),
rbs.mean$val.ext %>% mutate(metric = "rBS", type = "Train with duplicates, validate without duplicates"),
rbs.mean$train.ext %>% mutate(metric = "rBS", type = "Train without duplicates, validate with duplicates"))
metrics.comb <- rbind(metrics.mean_dedup %>% mutate(Deduplicated = "Yes"),
metrics.mean %>% mutate(Deduplicated = "No"))
ggplot(metrics.comb %>% filter(pFH == 0.7), aes(pDup, value)) +
geom_line(aes(color = factor(Deduplicated))) +
geom_point(aes(color = factor(Deduplicated))) +
geom_hline(data = metrics.comb %>% filter(pFH == 0.7, pDup == 0, Deduplicated == "No"),
aes(yintercept = value), linetype = "dashed") +
labs(x = "Proportion of families in original data with duplicates", y = "") +
scale_color_discrete(name = "Deduplicated") +
facet_grid(factor(metric, levels = c("O/E", "AUC", "rBS")) ~ type,
scales = "free",
switch = "y") +
theme(axis.title.y = element_blank(), # remove the default y-axis title, "wt"
strip.background.y = element_rect(fill = 'transparent'), # replace the strip backgrounds with transparent
strip.placement = 'outside', # put the facet strips on the outside
strip.text.y = element_text(angle = 180)) # rotate the y-axis text (optional)
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Simulation/snipR-Simulations/snipR-Simulations/Res_Sim_Effect_af01_dedup.RData")
getCI <- function(res, ndigits, comb = FALSE){
if(comb == TRUE){
paste0(format(round(mean(res), ndigits), nsmall = ndigits),
", (", format(round(sort(res)[3], ndigits), nsmall = ndigits),
", ", format(round(sort(res)[97], ndigits), nsmall = ndigits),
")")
} else{
c(format(round(mean(res), ndigits), nsmall = ndigits),
format(round(sort(res)[3], ndigits), nsmall = ndigits),
format(round(sort(res)[97], ndigits), nsmall = ndigits))
}
}
ndigits <- 3
res.oe <- res.auc <- res.rbs <-
lapply(setNames(vector("list", 3), c("cv", "val.ext", "train.ext")),
function(x){
z <- data.frame(matrix(NA, length(pDup.seq), length(pFH.seq)*3))
rownames(z) <- paste0("pDup_", pDup.seq)
colnames(z) <- apply(expand.grid(c("mean", "lo", "up"),
paste0("pFH_", pFH.seq))[, c(2, 1)], 1,
function(x) paste(x[1], x[2], sep = "_"))
return(z)
})
for(i in 1:length(pDup.seq)){
for(j in 1:length(pFH.seq)){
## training and validating on data with duplicates ##
res.oe$cv[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$OE_cv, ndigits)
res.auc$cv[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$AUC_cv, ndigits)
res.rbs$cv[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$rBS_cv, ndigits)
## training on data with duplicates, validating on external data set without duplicates ##
res.oe$val.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$OE_val.ext, ndigits)
res.auc$val.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$AUC_val.ext, ndigits)
res.rbs$val.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$rBS_val.ext, ndigits)
## training on external data without duplicates, validating on data with duplicates ##
res.oe$train.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$OE_train.ext, ndigits)
res.auc$train.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$AUC_train.ext, ndigits)
res.rbs$train.ext[i, (3*(j-1)+1):(3*j)] <- getCI(res.cv[[i]][[j]]$rBS_train.ext, ndigits)
}
}
## Plots ##
oe.mean <- lapply(lapply(res.oe, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
auc.mean <- lapply(lapply(res.auc, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
rbs.mean <- lapply(lapply(res.rbs, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
metrics.mean <- rbind(oe.mean$cv %>% mutate(metric = "O/E", type = "CV with duplicates"),
oe.mean$val.ext %>% mutate(metric = "O/E", type = "Train with duplicates, validate without duplicates"),
oe.mean$train.ext %>% mutate(metric = "O/E", type = "Train without duplicates, validate with duplicates"),
auc.mean$cv %>% mutate(metric = "AUC", type = "CV with duplicates"),
auc.mean$val.ext %>% mutate(metric = "AUC", type = "Train with duplicates, validate without duplicates"),
auc.mean$train.ext %>% mutate(metric = "AUC", type = "Train without duplicates, validate with duplicates"),
rbs.mean$cv %>% mutate(metric = "rBS", type = "CV with duplicates"),
rbs.mean$val.ext %>% mutate(metric = "rBS", type = "Train with duplicates, validate without duplicates"),
rbs.mean$train.ext %>% mutate(metric = "rBS", type = "Train without duplicates, validate with duplicates"))
ggplot(metrics.mean, aes(pDup, value)) +
geom_line(aes(color = factor(pFH))) +
geom_point(aes(color = factor(pFH))) +
labs(x = "Proportion of families in original data with duplicates", y = "") +
scale_color_discrete(name = "Among duplicates,\nproportion with \nextensive family \nhistory") +
facet_grid(factor(metric, levels = c("O/E", "AUC", "rBS")) ~ type,
scales = "free",
switch = "y") +
theme(axis.title.y = element_blank(), # remove the default y-axis title, "wt"
strip.background.y = element_rect(fill = 'transparent'), # replace the strip backgrounds with transparent
strip.placement = 'outside', # put the facet strips on the outside
strip.text.y = element_text(angle = 180)) # rotate the y-axis text (optional)
metrics.mean_dedup <- metrics.mean
load(paste0(getwd(), "/Res_Sim_Effect_af01.RData"))
oe.mean <- lapply(lapply(res.oe, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
auc.mean <- lapply(lapply(res.auc, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
rbs.mean <- lapply(lapply(res.rbs, function(x) x %>% select(ends_with("mean"))),
function(x){
pivot_longer(x, cols = starts_with("pFH")) %>%
transmute(value = as.numeric(value),
pDup = rep(pDup.seq, each = length(pFH.seq)),
pFH = rep(pFH.seq, length(pDup.seq)))
})
metrics.mean <- rbind(oe.mean$cv %>% mutate(metric = "O/E", type = "CV with duplicates"),
oe.mean$val.ext %>% mutate(metric = "O/E", type = "Train with duplicates, validate without duplicates"),
oe.mean$train.ext %>% mutate(metric = "O/E", type = "Train without duplicates, validate with duplicates"),
auc.mean$cv %>% mutate(metric = "AUC", type = "CV with duplicates"),
auc.mean$val.ext %>% mutate(metric = "AUC", type = "Train with duplicates, validate without duplicates"),
auc.mean$train.ext %>% mutate(metric = "AUC", type = "Train without duplicates, validate with duplicates"),
rbs.mean$cv %>% mutate(metric = "rBS", type = "CV with duplicates"),
rbs.mean$val.ext %>% mutate(metric = "rBS", type = "Train with duplicates, validate without duplicates"),
rbs.mean$train.ext %>% mutate(metric = "rBS", type = "Train without duplicates, validate with duplicates"))
metrics.comb <- rbind(metrics.mean_dedup %>% mutate(Deduplicated = "Yes"),
metrics.mean %>% mutate(Deduplicated = "No"))
ggplot(metrics.comb %>% filter(pFH == 0.7), aes(pDup, value)) +
geom_line(aes(color = factor(Deduplicated))) +
geom_point(aes(color = factor(Deduplicated))) +
geom_hline(data = metrics.comb %>% filter(pFH == 0.7, pDup == 0, Deduplicated == "No"),
aes(yintercept = value), linetype = "dashed") +
labs(x = "Proportion of families in original data with duplicates", y = "") +
scale_color_discrete(name = "Deduplicated") +
facet_grid(factor(metric, levels = c("O/E", "AUC", "rBS")) ~ type,
scales = "free",
switch = "y") +
theme(axis.title.y = element_blank(), # remove the default y-axis title, "wt"
strip.background.y = element_rect(fill = 'transparent'), # replace the strip backgrounds with transparent
strip.placement = 'outside', # put the facet strips on the outside
strip.text.y = element_text(angle = 180)) # rotate the y-axis text (optional)
metrics.comb %>% filter(pFH == 0.7)
metrics.comb %>% filter(pFH == 0.7, pDup == 0.35)
metrics.comb %>% filter(pFH == 0.7, pDup == "0.35")
metrics.comb %>% filter(pFH == 0.7, pDup == "0.35", metric == "OE")
metrics.comb %>% filter(pFH == 0.7, pDup == "0.35", metric == "O/E")
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Simulation/snipR-Simulations/snipR-Simulations/Res_Sim_Effect_af01.RData")
dat.summ[1,]
dat.summ[1:5,]
res.cv.orig
ind.i <- sample(1:nrow(dat.summ), nrow(dat.summ)/2)
mod.i <- glm(BRCA ~ proBC + proOC + relBC + relOC + proAge,
data = dat.summ[ind.i, ], family = "binomial")
pred.i <- predict(mod.i, dat.summ[-ind.i, ], type = "response")
auc(BRCA ~ pred.i, data = dat.summ[-ind.i, ])
plot(pred.i, dat.summ$BRCA[-ind.i])
dat.summ[1:5,]
dat.summ %>% filter(BRCA == 1) %>% select(proBC) %>% table()
dat.summ %>% filter(BRCA == 1) %>% select(proBC)
dat.summ %>% filter(BRCA == 1) %>% select(proBC) %>% sum()
nrow(dat.summ)
ind.i
length(indi)
length(ind.i)
summary(mod.i)
dat.summ %>% filter(BRCA == 1) %>% select(relBC) %>% summary()
dat.summ %>% filter(BRCA == 0) %>% select(relBC) %>% summary()
dat.summ01 <- dat.summ
res.cv.orig01 <- res.cv.orig
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Simulation/snipR-Simulations/snipR-Simulations/Res_Sim_Effect_af001.RData")
dat.summ001 <- dat.summ
res.cv.orig001 <- res.cv.orig
dat.summ01 %>% filter(BRCA == 1) %>% select(relBC) %>% summary()
dat.summ001 %>% filter(BRCA == 1) %>% select(relBC) %>% summary()
dat.summ01 %>% filter(BRCA == 0) %>% select(relBC) %>% summary()
dat.summ001 %>% filter(BRCA == 0) %>% select(relBC) %>% summary()
dat.summ01 %>% filter(BRCA == 1) %>% select(proBC) %>% summary()
dat.summ01 %>% filter(BRCA == 0) %>% select(proBC) %>% summary()
dat.summ001 %>% filter(BRCA == 1) %>% select(proBC) %>% summary()
dat.summ001 %>% filter(BRCA == 0) %>% select(proBC) %>% summary()
library(snipR)
library(tidyverse)
library(ggplot2)
library(reshape2)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## loading results ##
path <- paste0(getwd(), "/Sim_Param_Results")
files <- list.files(path, full.names = TRUE)
for(i in 1:length(files[!file.info(files)$isdir])){
load(paste0(path, "/res_sim_params_summ_", i, ".RData"))
if(i == 1){
res.param.tot <- res.param
} else{
res.param.tot <- rbind(res.param.tot, res.param)
}
}
res.param <- res.param.tot
## collecting results ##
res.param.avg <- res.param %>%
group_by(numNeighbors, snReps, keyLength, threshold, threshType) %>%
summarize(runtime = mean(runtime),
pairPrecision = mean(pairPrecision),
pairRecall = mean(pairRecall),
pairF1 = mean(pairF1),
clusterPrecision = mean(clusterPrecision),
clusterRecall = mean(clusterRecall),
clusterF1 = mean(clusterF1),
GMD = mean(GMD)) %>%
ungroup()
res.param.avg %>%
slice_max(pairF1, n = 10, with_ties = FALSE) %>%
print(width = Inf)
## summary table ##
library(xtable)
print(xtable(res.param.avg %>%
slice_min(GMD, n = 10, with_ties = FALSE) %>%
select(-threshType) %>%
as.data.frame(),
digits = c(0, 0, 0, 0, 0, 2, 3, 3, 3, 3, 3, 3, 1)),
include.rownames = FALSE)
res.long <- reshape2::melt(res.param.avg,
id.vars = c("numNeighbors", "snReps", "keyLength", "threshold"),
measure.vars = c("pairPrecision", "pairRecall", "pairF1",
"clusterPrecision", "clusterRecall", "clusterF1",
"GMD"),
variable.name = "metric")
## pairwise F1, cluster F1, and GMD in one plot
ggplot(res.long %>% filter(threshold %in% 4:7,
metric %in% c("pairF1", "clusterF1", "GMD")) %>%
mutate(value = case_when(metric == "GMD" ~ value /
max(res.long %>%
filter(threshold %in% 4:7, metric == "GMD") %>%
select(value), na.rm = TRUE),
TRUE ~ value)),
aes(numNeighbors, value)) +
geom_line(aes(color = factor(snReps), linetype = factor(metric))) +
geom_point(aes(color = factor(snReps), shape = factor(metric)), size = 1.7) +
labs(y = "", x = "Sliding window size", linetype = "Metric", shape = "Metric") +
scale_color_discrete(name = "Number of sort \nkey iterations") +
scale_linetype_discrete(labels = c("Pairwise F1", "Cluster F1", "GMD")) +
scale_shape_discrete(labels = c("Pairwise F1", "Cluster F1", "GMD")) +
facet_grid(keyLength ~ threshold,
labeller = labeller(keyLength = function(x) paste0("Key length: ", x),
threshold = function(x) paste0("Threshold: ", x)))
ggplot(res.long %>% filter(threshold %in% 4:7, metric == "pairF1"), aes(numNeighbors, value)) +
geom_line(aes(color = factor(snReps))) +
geom_point(aes(color = factor(snReps)), size = 1) +
labs(y = "Pairwise F1", x = "Sliding window size") +
scale_color_discrete(name = "Number of sort \nkey iterations") +
scale_linetype_discrete(name = "Metric") +
facet_grid(keyLength ~ threshold,
labeller = labeller(keyLength = function(x) paste0("Key length: ", x),
threshold = function(x) paste0("Threshold: ", x)))
ggplot(res.long %>% filter(threshold %in% 4:7, metric == "clusterF1"), aes(numNeighbors, value)) +
geom_line(aes(color = factor(snReps))) +
geom_point(aes(color = factor(snReps)), size = 1) +
labs(y = "Cluster F1", x = "Sliding window size") +
scale_color_discrete(name = "Number of sort \nkey iterations") +
scale_linetype_discrete(name = "Metric") +
facet_grid(keyLength ~ threshold,
labeller = labeller(keyLength = function(x) paste0("Key length: ", x),
threshold = function(x) paste0("Threshold: ", x)))
ggplot(res.long %>% filter(threshold %in% 4:7, metric == "GMD"), aes(numNeighbors, value)) +
geom_line(aes(color = factor(snReps))) +
geom_point(aes(color = factor(snReps)), size = 1) +
labs(y = "GMD", x = "Sliding window size") +
scale_color_discrete(name = "Number of sort \nkey iterations") +
scale_linetype_discrete(name = "Metric") +
facet_grid(keyLength ~ threshold,
labeller = labeller(keyLength = function(x) paste0("Key length: ", x),
threshold = function(x) paste0("Threshold: ", x)))
library(PanelPRO)
PanelPRO:::checkGeneCancerAssociations()
load("riskServ_Jan2018.RData")
load("counselee_with_request_Jan2018.RData")
riskServ <- riskServ %>% mutate(AJ = case_when(Ethnic == "AJ" ~ 1,
Ethnic == "nonAJ" ~ 0),
isProband = as.numeric(relationship == "Self"))
riskServ <- left_join(riskServ, counselee %>%
mutate(date = strptime(dateTime, "%Y-%m-%d %H:%M:%S"),
IPnum = as.numeric(senderIP)) %>%
select(requestId, date, IPnum),
by = "requestId")
riskServ <- riskServ %>%
group_by(requestId) %>%
mutate(famSize = n()) %>%
ungroup() %>%
as.data.frame()
load("/Users/thuang/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Risk Service Data Analysis/riskServ_Jan2018.RData")
load("/Users/thuang/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Risk Service Data Analysis/counselee_with_request_Jan2018.RData")
riskServ <- riskServ %>% mutate(AJ = case_when(Ethnic == "AJ" ~ 1,
Ethnic == "nonAJ" ~ 0),
isProband = as.numeric(relationship == "Self"))
riskServ <- left_join(riskServ, counselee %>%
mutate(date = strptime(dateTime, "%Y-%m-%d %H:%M:%S"),
IPnum = as.numeric(senderIP)) %>%
select(requestId, date, IPnum),
by = "requestId")
riskServ <- riskServ %>%
group_by(requestId) %>%
mutate(famSize = n()) %>%
ungroup() %>%
as.data.frame()
riskServ[1:3,]
nrow(riskServ)
riskServ %>% group_by(requestId) %>% select(famSize) %>% table()
riskServ %>% filter(isProband == 1) %>% select(famSize) %>% table()
sum(penet.brca.net$fFX[, "B10"])
sum(penet.brca.net$fFX[1:75, "B10"])
0.7*0.3*1.96^2/0.05^2
brcaparams()$allef
penet.brca.net$fFX[1:70, "B00"]
sum(penet.brca.net$fFX[1:70, "B00"])
sum(penet.brca.net$fFX[1:70, "B10"])
brcaparams$allef()
brcaparams()$allef
brcaparams()$allef[[1]][1]*2
brcaparams()$allef[[1]][2]*2
1 - (1 - brcaparams()$allef[[1]][2])^2
af <- 1 - (1 - brcaparams()$allef[[1]][2])^2
af*sum(penet.brca.net$fFX[1:70, "B10"]) + (1-af)*sum(penet.brca.net$fFX[1:70, "B00"])
14934*0.0271382
library(PanelPRO)
PanelPRO:::checkGeneCancerAssociations()
ls()
riskServ %>% filter(isProband == 1) %>% select(famSize) %>% table()
riskServ %>% filter(isProband == 1) %>% select(famSize) %>% hist()
riskServ %>% filter(isProband == 1) %>% select(famSize) %>% as.numeric() %>% hist()
riskServ %>% filter(isProband == 1) %>% select(famSize) %>% as.matrix() %>% as.numeric() %>% hist()
riskServ %>% filter(isProband == 1) %>% select(famSize) %>% summary()
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Simulation/snipR-Simulations/snipR-Simulations/Sim_Dup_Dat.RData")
ls()
dat.tot[1,]
dat.tot %>% filter(isProband == 1) %>% select(famSize) %>% summary()
dat.tot %>% filter(isProband == 1) %>% select(famSize) %>% as.matrix() %>% summary()
dat.tot %>% filter(isProband == 1) %>% select(famSize) %>% as.matrix() %>% as.numeric() %>% summary()
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Risk Service Data Analysis/res_riskserv_sw10_1.RData")
res.dup$dupsReps$thresh_5[1:5]
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Risk Service Data Analysis/res_riskserv_sw20_1.RData")
res.dup$dupsReps$thresh_7[1:5]
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Risk Service Data Analysis/riskservice_dedup_sw20t7.RData")
dat.dedup20_7 %>% filter(isProband == 1) %>% select(famSize) %>% summary()
riskServ %>% filter(isProband == 1) %>% select(famSize) %>% summary()
dat.dedup20_7 %>% filter(isProband == 1) %>% nrow()
riskServ %>% filter(isProband == 1) %>% nrow()
load("~/Dropbox (Partners HealthCare)/BayesMendel Dropbox folders/Deduplication Paper/Simulation/Sim_Dup_Dat.RData")
